# 🤖 AI Interviewer Agent – *Interview Mind*

**[Interview Mind](https://interview-mind.onrender.com/)** is an intelligent, adaptive mock interview system powered by cutting-edge LLMs. It simulates a technical interviewer who dynamically asks conceptual questions, scores your responses on clarity, accuracy, and depth, and gives a detailed performance summary — all in a beautiful, web-based interface.

> 🎯 Ideal for learners, job seekers, or anyone wanting to test their foundational tech knowledge.

---

## 🔗 Live Links

- 🌐 **Live Demo:** [https://interview-mind.onrender.com/](https://interview-mind.onrender.com/) 
- 📦 **GitHub Repo:** [https://github.com/Agaramsaikrishna/interview-mind](https://github.com/Agaramsaikrishna/interview-mind)
  
  > **Note:** The live demo is hosted on a free instance that may spin down during inactivity, which can cause initial response delays.

---

## 🚀 Setup Instructions

### ✅ Prerequisites
- Python 3.9+
- `pip` (Python package manager)

### 1. Clone the Repository
```bash
git clone https://github.com/Agaramsaikrishna/interview-mind.git
cd interview-mind
```
### 2. Create a Virtual Environment
```
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```
pip install -r requirements.txt
```
Note: If requirements.txt is missing, you can generate it after installing your packages using:
```
pip freeze > requirements.txt
```

### 4. Set Up API Keys
This app uses Groq’s LLaMA 3 model for LLM capabilities.

Go to Groq Console and get your API key.

Create a .env file in the root of your project.

Add your API configuration like this:

```
GROQ_API_KEY="your_groq_api_key_here"
GROQ_LLAMA_3_8B="llama-3.1-8b-instant"
```
### 5. Run the App (Streamlit UI)
```
streamlit run app.py
```
This will launch a local server and open the app in your browser.

### 🧠 Technologies Used
Technology	Purpose
Python 3.9+	Main programming language
LangChain	LLM integration, memory & prompt templates
LangGraph	Graph-based control flow & branching
Streamlit	Interactive web UI
Groq API	Ultra-fast hosted LLMs (LLaMA 3)
dotenv	Secure API key management
numpy	Score calculation (averages, etc.)

```
interview-mind/
├── app.py               # Main Streamlit app
├── requirements.txt
├── .env                 # Your API keys (not committed)
└── src/
    ├── config.py        # LLM initialization logic
    ├── prompts.py       # Prompt templates
    ├── nodes.py         # Interview question/evaluation logic
    ├── state.py         # State definition (question/score tracking)
    └── graph.py         # LangGraph workflow

```

### 🔄 Interview Flow (LangGraph)

```
START
  ↓
Select Topic & Begin Interview
  ↓
Ask Conceptual Question
  • Dynamically generated by the LLM based on selected topic
  ↓
User Submits Answer
  ↓
LLM Evaluates Answer
  • Scored on Accuracy, Clarity, and Depth (0–10 scale)
  ↓
┌──────────────────────────────────────────────┐
│ Is score < 6 AND follow-up not yet given?    │
└──────────────────────────────────────────────┘
        ↓                             ↓
     Yes                             No
      ↓                               ↓
 Ask Follow-Up Question        Ask Next Main Question
  • Simplified/clarifying       • Continue to next core topic
    version of the question
      ↓                               ↓
  User Submits Answer          User Submits Answer
      ↓                               ↓
     [Repeat Evaluation and Decision Logic]
        ↓
Repeat Until 3–5 Main Questions Answered
  ↓
Generate Interview Summary & Feedback
  • Includes overall scores, strengths, areas for improvement
  • Presented in structured Markdown format
  ↓
END


```
Key Logic Highlights
Follow-Ups: If a user struggles (score < 6), a simpler clarifying question is asked.

Question Memory: Avoids repetition using full state tracking.

Scoring Rubric: Evaluates based on clarity, accuracy, and depth. Each scored 0–10.

Summarization: Provides markdown-formatted summary with strengths, weaknesses, advice, and recommendation.

🌟 Features
| Feature                        | Description                                         |
| ------------------------------ | --------------------------------------------------- |
| ✅ **LLM-Powered Interviewer** | Dynamically asks and evaluates tech questions       |
| ✅ **Streamlit Frontend**      | Clean and interactive UI                            |
| ✅ **Branching Logic**         | Adjusts flow based on answer quality                |
| ✅ **Follow-Up Questions**     | Gives hints or simpler versions if needed           |
| ✅ **Multiple Topics**         | Can handle multi-topic interviews                   |
| ✅ **LLM Flexibility**         | Easily switch to Together AI, OpenAI, or local LLMs |
| ✅ **Performance Summary**     | Full feedback and scores shown after the interview  |

📊 Scoring Dimensions

| Criteria     | Meaning                             |
| ------------ | ----------------------------------- |
| **Accuracy** | Technical correctness of the answer |
| **Clarity**  | How clearly the answer is explained |
| **Depth**    | Completeness, insight, and nuance   |
| **Overall**  | Combined average score              |

📈 Example (Live App) 

1. Open https://interview-mind.onrender.com

2. Enter a topic like Python, Machine Learning, or JavaScript

3. Rate your skill level (1–10)

4. Answer each question → Get instant feedback

5. End of interview: see a detailed summary with average scores, improvement advice, and hiring recommendation


## ✅ Checklist Review 

### 🧠 Objective 
| Requirement                                        | Met? | Notes                                          |
| -------------------------------------------------- | ---- | ---------------------------------------------- |
| Simulates a technical interviewer                  | ✅    | Conducts interactive interviews via LLM        |
| Asks 3–5 dynamically generated technical questions | ✅    | Uses topic input and dynamic LLM prompts       |
| Responds intelligently & optionally scores         | ✅    | Scores answers on clarity, accuracy, and depth |
| Summarizes and gives feedback at end               | ✅    | Generates structured summary with markdown     |
| Branching logic based on responses                 | ✅    | Follow-up if score < 6, else next question     |


### ⚙️ Requirements 

| Component                         | Met? | Notes                                                                          |
| --------------------------------- | ---- | -----------------------------------------------------------------------------  |
| LangGraph / LangChain used        | ✅    | Uses **LangGraph** (preferred) for flow                                       |
| LLM Integration                   | ✅    | Uses **Groq (LLaMA 3)** with option to switch to others                       |
| Branching logic for adaptive flow | ✅    | Follow-up vs. next question based on score                                    |
| Memory/state management           | ✅    | Manages full interview state in LangGraph                                     |
| Prompt engineering                | ✅    | Prompts designed for follow-up logic, anti-repetition, and summary formatting |


### ✨ Bonus Features 
| Feature                                   | Met? | Notes                                     |
| ----------------------------------------- | ---- | ----------------------------------------- |
| Vector Store                              | ❌    | Not implemented (optional)               |
| Answer Scoring (accuracy, clarity, depth) | ✅    | Done                                     |


### 📦 Deliverables 
| Deliverable                   | Met? | Notes                                                                                                     |
| ----------------------------- | ---- | --------------------------------------------------------------------------------------------------------  |
| GitHub Repo                   | ✅    | [https://github.com/Agaramsaikrishna/interview-mind](https://github.com/Agaramsaikrishna/interview-mind) |
| Live Demo                     | ✅    | [https://interview-mind.onrender.com](https://interview-mind.onrender.com)                               |
| README with required sections | ✅    | Includes setup, tech used, branching logic, optional features                                            |


✅ Conclusion
🎉 Yes, your project fully satisfies the pre-work requirements and even goes beyond by implementing optional scoring, a polished Streamlit UI, and LangGraph-based branching logic.


 
