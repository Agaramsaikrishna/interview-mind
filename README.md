# ğŸ¤– AI Interviewer Agent â€“ *Interview Mind*

**[Interview Mind](https://interview-mind.onrender.com/)** is an intelligent, adaptive mock interview system powered by cutting-edge LLMs. It simulates a technical interviewer who dynamically asks conceptual questions, scores your responses on clarity, accuracy, and depth, and gives a detailed performance summary â€” all in a beautiful, web-based interface.

> ğŸ¯ Ideal for learners, job seekers, or anyone wanting to test their foundational tech knowledge.

---

## ğŸ”— Live Links

- ğŸŒ **Live Demo:** [https://interview-mind.onrender.com/](https://interview-mind.onrender.com/) 
- ğŸ“¦ **GitHub Repo:** [https://github.com/Agaramsaikrishna/interview-mind](https://github.com/Agaramsaikrishna/interview-mind)
  
  > **Note:** The live demo is hosted on a free instance that may spin down during inactivity, which can cause initial response delays.

---

## ğŸš€ Setup Instructions

### âœ… Prerequisites
- Python 3.9+
- `pip` (Python package manager)

### 1. Clone the Repository
```bash
git clone https://github.com/Agaramsaikrishna/interview-mind.git
cd interview-mind
```
### 2. Create a Virtual Environment
```
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies
```
pip install -r requirements.txt
```
Note: If requirements.txt is missing, you can generate it after installing your packages using:
```
pip freeze > requirements.txt
```

### 4. Set Up API Keys
This app uses Groqâ€™s LLaMA 3 model for LLM capabilities.

Go to Groq Console and get your API key.

Create a .env file in the root of your project.

Add your API configuration like this:

```
GROQ_API_KEY="your_groq_api_key_here"
GROQ_LLAMA_3_8B="llama-3.1-8b-instant"
```
### 5. Run the App (Streamlit UI)
```
streamlit run app.py
```
This will launch a local server and open the app in your browser.

### ğŸ§  Technologies Used
Technology	Purpose
Python 3.9+	Main programming language
LangChain	LLM integration, memory & prompt templates
LangGraph	Graph-based control flow & branching
Streamlit	Interactive web UI
Groq API	Ultra-fast hosted LLMs (LLaMA 3)
dotenv	Secure API key management
numpy	Score calculation (averages, etc.)

```
interview-mind/
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                 # Your API keys (not committed)
â””â”€â”€ src/
    â”œâ”€â”€ config.py        # LLM initialization logic
    â”œâ”€â”€ prompts.py       # Prompt templates
    â”œâ”€â”€ nodes.py         # Interview question/evaluation logic
    â”œâ”€â”€ state.py         # State definition (question/score tracking)
    â””â”€â”€ graph.py         # LangGraph workflow

```

### ğŸ”„ Interview Flow (LangGraph)

```
START
  â†“
Select Topic & Begin Interview
  â†“
Ask Conceptual Question
  â€¢ Dynamically generated by the LLM based on selected topic
  â†“
User Submits Answer
  â†“
LLM Evaluates Answer
  â€¢ Scored on Accuracy, Clarity, and Depth (0â€“10 scale)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Is score < 6 AND follow-up not yet given?    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“                             â†“
     Yes                             No
      â†“                               â†“
 Ask Follow-Up Question        Ask Next Main Question
  â€¢ Simplified/clarifying       â€¢ Continue to next core topic
    version of the question
      â†“                               â†“
  User Submits Answer          User Submits Answer
      â†“                               â†“
     [Repeat Evaluation and Decision Logic]
        â†“
Repeat Until 3â€“5 Main Questions Answered
  â†“
Generate Interview Summary & Feedback
  â€¢ Includes overall scores, strengths, areas for improvement
  â€¢ Presented in structured Markdown format
  â†“
END


```
Key Logic Highlights
Follow-Ups: If a user struggles (score < 6), a simpler clarifying question is asked.

Question Memory: Avoids repetition using full state tracking.

Scoring Rubric: Evaluates based on clarity, accuracy, and depth. Each scored 0â€“10.

Summarization: Provides markdown-formatted summary with strengths, weaknesses, advice, and recommendation.

ğŸŒŸ Features
| Feature                        | Description                                         |
| ------------------------------ | --------------------------------------------------- |
| âœ… **LLM-Powered Interviewer** | Dynamically asks and evaluates tech questions       |
| âœ… **Streamlit Frontend**      | Clean and interactive UI                            |
| âœ… **Branching Logic**         | Adjusts flow based on answer quality                |
| âœ… **Follow-Up Questions**     | Gives hints or simpler versions if needed           |
| âœ… **Multiple Topics**         | Can handle multi-topic interviews                   |
| âœ… **LLM Flexibility**         | Easily switch to Together AI, OpenAI, or local LLMs |
| âœ… **Performance Summary**     | Full feedback and scores shown after the interview  |

ğŸ“Š Scoring Dimensions

| Criteria     | Meaning                             |
| ------------ | ----------------------------------- |
| **Accuracy** | Technical correctness of the answer |
| **Clarity**  | How clearly the answer is explained |
| **Depth**    | Completeness, insight, and nuance   |
| **Overall**  | Combined average score              |

ğŸ“ˆ Example (Live App) 

1. Open https://interview-mind.onrender.com

2. Enter a topic like Python, Machine Learning, or JavaScript

3. Rate your skill level (1â€“10)

4. Answer each question â†’ Get instant feedback

5. End of interview: see a detailed summary with average scores, improvement advice, and hiring recommendation


## âœ… Checklist Review 

### ğŸ§  Objective 
| Requirement                                        | Met? | Notes                                          |
| -------------------------------------------------- | ---- | ---------------------------------------------- |
| Simulates a technical interviewer                  | âœ…    | Conducts interactive interviews via LLM        |
| Asks 3â€“5 dynamically generated technical questions | âœ…    | Uses topic input and dynamic LLM prompts       |
| Responds intelligently & optionally scores         | âœ…    | Scores answers on clarity, accuracy, and depth |
| Summarizes and gives feedback at end               | âœ…    | Generates structured summary with markdown     |
| Branching logic based on responses                 | âœ…    | Follow-up if score < 6, else next question     |


### âš™ï¸ Requirements 

| Component                         | Met? | Notes                                                                          |
| --------------------------------- | ---- | -----------------------------------------------------------------------------  |
| LangGraph / LangChain used        | âœ…    | Uses **LangGraph** (preferred) for flow                                       |
| LLM Integration                   | âœ…    | Uses **Groq (LLaMA 3)** with option to switch to others                       |
| Branching logic for adaptive flow | âœ…    | Follow-up vs. next question based on score                                    |
| Memory/state management           | âœ…    | Manages full interview state in LangGraph                                     |
| Prompt engineering                | âœ…    | Prompts designed for follow-up logic, anti-repetition, and summary formatting |


### âœ¨ Bonus Features 
| Feature                                   | Met? | Notes                                     |
| ----------------------------------------- | ---- | ----------------------------------------- |
| Vector Store                              | âŒ    | Not implemented (optional)               |
| Answer Scoring (accuracy, clarity, depth) | âœ…    | Done                                     |


### ğŸ“¦ Deliverables 
| Deliverable                   | Met? | Notes                                                                                                     |
| ----------------------------- | ---- | --------------------------------------------------------------------------------------------------------  |
| GitHub Repo                   | âœ…    | [https://github.com/Agaramsaikrishna/interview-mind](https://github.com/Agaramsaikrishna/interview-mind) |
| Live Demo                     | âœ…    | [https://interview-mind.onrender.com](https://interview-mind.onrender.com)                               |
| README with required sections | âœ…    | Includes setup, tech used, branching logic, optional features                                            |


âœ… Conclusion
ğŸ‰ Yes, your project fully satisfies the pre-work requirements and even goes beyond by implementing optional scoring, a polished Streamlit UI, and LangGraph-based branching logic.


 
